# UAV-TVT In progress

This repository is created and shared for the following paper.
> Soltani, Nasim, et al. "RF Fingerprinting Unmanned Aerial Vehicles with Non-standard Transmitter Waveforms." IEEE Transactions on Vehicular Technology 69.12 (2020): 15518-15531. 
	https://ieeexplore.ieee.org/document/9277909/

> Dataset page: 	https://genesys-lab.org/hovering-uavs

## Steps to use the code:

1. Download the dataset from the above page.
2. Convert the dataset from SigMF format to .mat files using sigmf_reader.py
3. Preprocess the .mat files to generate train/validation/test partitions using pre_process_uav.py
4. Run the ML code using the bash script run_ML_code.sh (You need to edit the paths inside the .sh file.)
5. Aggregate the saved predictions using preds_aggregator.py

### 1. Download the dataset file:
Download the dataset file and unzip it. Save the folder in a `UAV-TVT` folder in your desired path.

### 2. Convert from SigMF:
Follow the comments on the top of `sigmf_reader.py`, adjust your paths and convert from SigMF folder to `.mat` files that are readable for `ML_code`.

### 3. Preprocess the .mat files:
The `.mat` files containing sub-examples need to be preprocessed to form the training/test partitions and calculate mean and standard deviation, that are used by the `ML_code`. All the necessary inputs for the `ML_code` are generated by running `pre_process_uav.py`

The preprocessing step generates 4 pickle files:

1. `Partition.pkl`: Contains train/val/test partitions which are lists of paths to the corresponding `.mat` files.
2. `stats.pkl`: Contains information about the dataset including mean and standard deviation of the training set.
3. `label.pkl`: Contains a dictionary that associates each mat file with a device name (class name).
4. `device_ids.pkl`: Contains a dictionary that associates each device name with a class index.

### 4. Run the ML_code using the bash file:

	python -u /home/nasim/UAVFramework/ML_code/top.py \
	--exp_name $1 \
	--partition_path /home/nasim/UAV-TVT/PklFiles/cnn1/ \
	--stats_path /home/nasim/UAV-TVT/PklFiles/cnn1/ \
	--save_path /home/nasim/UAV-TVT/results/ \
	--model_flag alexnet \
	--contin false \
	--json_path /home/nasim/UAV-TVT/results/cnn1/model_file.json \
	--hdf5_path /home/nasim/UAV-TVT/results/cnn1/model.hdf5 \
	--slice_size 200 \
	--num_classes 7 \
	--batch_size 256 \
	--id_gpu $2 \
	--normalize true \
	--train true \
	--test true \
	--epochs 100 \
	--early_stopping true \
	--patience 5 \
	> /home/nasim/UAV-TVT/results/$1/log.out \
	2> /home/nasim/UAV-TVT/results/$1/log.err
	
- python -u path_to_top.py
- exp_name: An optional name for this experiment. This name will also be the name of the folder your results will be saved to.
- partition_path: Path to the `partition.pkl` file generated from pre-processing step.
- stats_path: Path to the stats.pkl file generated from pre-processing step. (if you are training, this will be the same as your partition_path)
- save_path: Path to the result folder on your system.
- model_flag: A switch to use either of the models in the paper, alexnet or resnet. Please note that our alexnet is a modified version of the famous AlexNet, and is not exactly the same.
- contin: Set to true if you want to load a pre-trained model and continue training/testing from there.
- json_path: If conin is set to true, this argument represents the structure file path for the pre-trained model.
- hdf5_path: If conin is set to true, this argument represents the weight file path for the pre-trained model.
- slice_size: Input size of the NN also known as slice size in the paper.
- num_classes: Number of UAVs you want to fingerprint. This argument determines the output size of the NN.
- batch_size: Your desired batch size for training.
- id_gpu: The GPU id you like to use for training/test.
- normalize: Set to true if you wish to normalize data for training/test.
- train: Set to true if you want to train a network.
- test: Set to true if you want to test a nework.
- epochs: The number of epochs you wish to run training for.
- early_stopping: Set to true if you wish to stop earlier than the number of epochs determined above.
- patience: If early stopping is set to true, the training stops after the validation accuracy does not improve for this many consecutive epochs.
- The last two lines specify where you want to write the output log and error log in the result folder.

The `ML_code` saves the trained model structure and weight, saves logs and a `preds.pkl` file in the experiment folder.
The slice and accuracy results are reported at the end of `log.out` file.

### 5. Aggregating the predictions:
The paper proposes a novel aggregation method that is implemented in `preds_aggregator.py` in this repository.

The `ML_code` generates one preds.pkl file after each test experiment, that contains all the predictions of that NN for the all the sub-examples in the whole test set. Running `preds_aggregator.py` generates the aggregated results.
